{"cells":[{"outputs":[],"execution_count":2,"source":"import sys\nsys.path.append('/home/kesci/input/d2l9528/')\nimport collections\nimport d2l\nimport zipfile\nfrom d2l.data.base import Vocab\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils import data\nfrom torch import optim","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"6AA9F09B70A4453A9A9DD564290F8B0B","scrolled":false}},{"metadata":{"id":"71881316D69849B6924D62228C33DFD2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Go.\tVa !\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\nHi.\tSalut !\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)\nHi.\tSalut.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)\nRun!\tCours !\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)\nRun!\tCourez !\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)\nWho?\tQui ?\tCC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #4366796 (gillux)\nWow!\tÇa alors !\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #374631 (zmoo)\nFire!\tAu feu !\tCC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #4627939 (sacredceltic)\nHelp!\tÀ l'aide !\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #128430 (sysko)\nJump.\tSaute.\tCC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #2416938 (Phoenix)\nStop!\tÇa suffit !\tCC-BY 2.0 (France) Attribution: tato\n","name":"stdout"}],"source":"# 读取语料\nwith open('/home/kesci/input/fraeng6506/fra.txt', 'r') as f:\n      raw_text = f.read()\nprint(raw_text[0:1000])","execution_count":3},{"metadata":{"id":"354603BE2E13434F81098528635A7AF1","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"查看清洗效果： go .\tva !\tcc-by 2 .0 (france) attribution: tatoeba .org #2877272 (cm) & #1158250 (wittydev)\nhi .\tsalut !\tcc-by 2 .0 (france) attribution: tatoeba .org #538123 (cm) & #509819 (aiji)\nhi .\tsalut .\tcc-by 2 .0 (france) attribution: tatoeba .org #538123 (cm) & #4320462 (gillux)\nrun !\tcours !\tcc-by 2 .0 (france) attribution: tatoeba .org #906328 (papabear) & #906331 (sacredceltic)\nrun !\tcourez !\tcc-by 2 .0 (france) attribution: tatoeba .org #906328 (papabear) & #906332 (sacredceltic)\nwho?\tqui ?\tcc-by 2 .0 (france) attribution: tatoeba .org #2083030 (ck) & #4366796 (gillux)\nwow !\tça alors !\tcc-by 2 .0 (france) attribution: tatoeba .org #52027 (zifre) & #374631 (zmoo)\nfire !\tau feu !\tcc-by 2 .0 (france) attribution: tatoeba .org #1829639 (spamster) & #4627939 (sacredceltic)\nhelp !\tà l'aide !\tcc-by 2 .0 (france) attribution: tatoeba .org #435084 (lukaszpp) & #128430 (sysko)\njump .\tsaute .\tcc-by 2 .0 (france) attribution: tatoeba .org #631038 (shishir) & #2416938 (phoenix)\nstop !\tça suffit !\tcc-b\n","name":"stdout"}],"source":"# 数据清洗\ndef preprocess_raw(text):\n    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n    out = ''\n    for i, char in enumerate(text.lower()):  # 转化小写\n        if char in (',', '!', '.') and i > 0 and text[i-1] != ' ':\n            out += ' '  # 加上空格，以此一一对应\n        out += char\n    return out\ntext = preprocess_raw(raw_text)\nprint(\"查看清洗效果：\", text[0:1000])","execution_count":4},{"metadata":{"id":"4D205D2E71504A1AA1D3A44D5AAE94EF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"([['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!']],\n [['va', '!'], ['salut', '!'], ['salut', '.'], ['cours', '!']])"},"transient":{},"execution_count":5}],"source":"# 分词操作。\nnum_examples = 50000  # 先去部分进行分词操作，看看效果\nsource, target = [], []\nfor i, line in enumerate(text.split('\\n')):  # 将英语和法语分别对应起来，放置同一列表\n    if i > num_examples:\n        break\n    parts = line.split('\\t')  # 以tab为分隔符\n    if len(parts) >= 2:\n        source.append(parts[0].split(' '))  # eng分割\n        target.append(parts[1].split(' '))  # fra分割\nsource[0:4], target[0:4]","execution_count":5},{"metadata":{"id":"354046DCFC6E48C1860BB47516B8B084","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"3789"},"transient":{},"execution_count":6}],"source":"# 建立词典类\nclass Vocab(object):\n    def __init__(self, tokens, min_freq=0, use_special_tokens=False):\n        counter = collections.Counter(tokens)\n        token_freqs = sorted(counter.items(), key=lambda x: x[0])\n        token_freqs.sort(key=lambda x: x[1], reverse=True)\n        if use_special_tokens:\n            self.pad, self.bos, self.eos, self.unk = (0, 1, 2, 3)\n            tokens = ['<pad>', '<bos>', '<eos>', '<unk>']\n        else:\n            self.unk = 0\n            tokens = ['<unk>']\n        tokens += [token for token, freq in token_freqs if freq >= min_freq]  # 去除出现频率过小的单词\n        self.idx_to_token = []\n        self.token_to_idx = dict()\n        for token in tokens:\n            self.idx_to_token.append(token)\n            self.token_to_idx[token] = len(self.idx_to_token) - 1\n    \n    def __len__(self):  # 专有方法重载\n        return len(self.idx_to_token)\n        \n    def __getitem__(self, tokens):  # 专有方法重载\n        if not isinstance(tokens, (list, tuple)):  # 判断类型\n            return self.token_to_idx.get(tokens, self.unk)\n        else:\n            return [self.__getitem__(token) for token in tokens]\n            \n# 建立词典\ndef build_dict(tokens):\n    word_list = [token for line in tokens for token in line]\n    # word_list = []\n    # for line in tokens:\n    #     for word in line:\n    #         word_list.append(word)\n    return Vocab(word_list, min_freq=3, use_special_tokens=True)\n\nsrc_vocab = build_dict(source)\nlen(src_vocab)","execution_count":6},{"metadata":{"id":"306A2B7B48744FE4AA9F1EDBB860A192","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"[38, 4, 0, 0, 0, 0, 0, 0, 0, 0]"},"transient":{},"execution_count":7}],"source":"# 补全语料长度（保证输入和输出长度一致）\ndef pad(line, max_len, padding_token):\n    if len(line) > max_len:  # 句子长度大于设定值，组需要切割\n        return line[:max_len]\n    return line + [padding_token] * (max_len - len(line))  # 用指定padding符合补全\npad(src_vocab[source[0]], 10, src_vocab.pad)","execution_count":7},{"metadata":{"id":"265E341F074148A086E825F146E5D630","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 接下来需要将每个句子组合起来\ndef build_array(lines, vocab, max_len, is_source):\n    # temp_lines = [vocab[line] for line in lines]\n    temp_lines = []\n    for line in lines:\n        temp_lines.append(vocab[line])  # 自动调用上述字典类Vocab的专有方法__getitem__\n    if not is_source:\n        temp_lines = [[vocab.bos] + line + [vocab.eos] for line in temp_lines]\n    array = torch.tensor([pad(line, max_len, vocab.pad) for line in temp_lines])  # 转化为符合训练的tensor格式\n    valid_len = (array != vocab.pad).sum(1) #第一个维度-计算语料有效长度，后期计算loss值有用处\n    return array, valid_len","execution_count":8},{"metadata":{"id":"8C526FF569B24A1F93E47A225F967ECD","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def load_data_nmt(batch_size, max_len): # This function is saved in d2l.\n    src_vocab, tgt_vocab = build_dict(source), build_dict(target)  # 分别建立源语料和目标语料词典\n    src_array, src_valid_len = build_array(source, src_vocab, max_len, True)  # 语料格式转化\n    tgt_array, tgt_valid_len = build_array(target, tgt_vocab, max_len, False)\n    # 利用pytorch内置函数TensorDataset将语料合并，以便后期训练\n    train_data = data.TensorDataset(src_array, src_valid_len, tgt_array, tgt_valid_len) \n    # 利用pytorch内置函数DataLoader将语料以batch_size批量分割\n    train_iter = data.DataLoader(train_data, batch_size, shuffle=True)\n    return src_vocab, tgt_vocab, train_iter","execution_count":9},{"metadata":{"id":"C7B66D53AAF7489FAB32093F1072D993","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"X = tensor([[   5,   48,   79,  140,    4,    0,    0,    0],\n        [  12,    8,    7, 1248,  383,    4,    0,    0]], dtype=torch.int32) \nValid lengths for X = tensor([5, 6]) \nY = tensor([[   1,    5,    9,  382,    7,   42,   60,    4],\n        [   1,   15,   14,   19, 4797,  624,    4,    2]], dtype=torch.int32) \nValid lengths for Y = tensor([8, 8])\n","name":"stdout"}],"source":"# 查看效果\nsrc_vocab, tgt_vocab, train_iter = load_data_nmt(batch_size=2, max_len=8)\nfor X, X_valid_len, Y, Y_valid_len, in train_iter:\n    print('X =', X.type(torch.int32), '\\nValid lengths for X =', X_valid_len,\n        '\\nY =', Y.type(torch.int32), '\\nValid lengths for Y =', Y_valid_len)\n    break","execution_count":10},{"metadata":{"id":"6AD8E484737548898A9B2B6A518B37BF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 以上处理好训练所需的数据（格式）\n# 接下来开始搭建网络\nclass Encoder(nn.Module):\n    def __init__(self, **kwargs):\n        super(Encoder, self).__init__(**kwargs)\n\n    def forward(self, X, *args):\n        raise NotImplementedError\n\nclass Decoder(nn.Module):\n    def __init__(self, **kwargs):\n        super(Decoder, self).__init__(**kwargs)\n\n    def init_state(self, enc_outputs, *args):\n        raise NotImplementedError\n\n    def forward(self, X, state):\n        raise NotImplementedError\n        \nclass EncoderDecoder(nn.Module):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(EncoderDecoder, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, enc_X, dec_X, *args):\n        enc_outputs = self.encoder(enc_X, *args)\n        dec_state = self.decoder.init_state(enc_outputs, *args)\n        return self.decoder(dec_X, dec_state)\n        \n        ","execution_count":11},{"metadata":{"id":"A91C1FA293414018910CEA5BB01D737B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 搭建seq2seq模型encoder部分-具体地以LSTM为基本单元\nclass Seq2SeqEncoder(d2l.Encoder):\n    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n                 dropout=0, **kwargs):\n        super(Seq2SeqEncoder, self).__init__(**kwargs)\n        self.num_hiddens = num_hiddens\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(vocab_size, embed_size)  #nn模块的词嵌入方法\n        self.rnn = nn.LSTM(embed_size, num_hiddens, num_layers, dropout=dropout)\n    \n    # 隐藏状态初始化\n    def begin_state(self, batch_size, device):\n        return [torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens), device=device),\n                torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens), device=device)]\n\n    def forward(self, X, *args):\n        # batch_size表*个句子，seq_len表每个句子*个单词，embedding_size表每个单词*维向量表示\n        X = self.embedding(X)  # embedding后shape:(batch_size, seq_len, embedding_size)\n        X = X.transpose(0, 1)  # 将第一和第二维度进行调换。 X shape:(seq_len, batch_size, embedding_size)\n        out, state = self.rnn(X)\n        # 输出的out包含每个隐藏状态 shape: (seq_len, batch_size, num_hiddens)\n        # state包含两个内容：最后一个时间步的隐层状态和记忆细胞 shape: (num_layers, batch_size, num_hiddens)\n    \n        return out, state","execution_count":12},{"metadata":{"id":"82333B9EA7454868846DDE5E6E222E9A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"(torch.Size([7, 4, 10]), 2, torch.Size([2, 4, 10]), torch.Size([2, 4, 10]))"},"transient":{},"execution_count":13}],"source":"# 人为构造输入语料，4个句子，7单词/句子\n# 观察下直观的效果\nx = torch.zeros((4, 7), dtype=torch.long)\nencoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=10, num_layers=2)\noutput, state = encoder(x)\noutput.shape, len(state), state[0].shape, state[1].shape","execution_count":13},{"metadata":{"id":"039D2B176D894D86AD0F7B450FB15DF4","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 接下来是Seq2seq模型decoder部分\nclass Seq2SeqDecoder(d2l.Decoder):\n    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n                 dropout=0, **kwargs):\n        super(Seq2SeqDecoder, self).__init__(**kwargs)\n        self.embedding = nn.Embedding(vocab_size, embed_size)  #nn模块的词嵌入方法\n        self.rnn = nn.LSTM(embed_size, num_hiddens, num_layers, dropout=dropout)\n        self.dense = nn.Linear(num_hiddens,vocab_size)  # 全连接层。用于映射至词典大小维度，方便后续匹配词向量\n    \n    # encoder作为输入的隐藏状态\n    def init_state(self, enc_outputs, *args):\n        return enc_outputs[1]\n    \n    def forward(self, X, *args):\n        # batch_size表*个句子，seq_len表每个句子*个单词，embedding_size表每个单词*维向量表示\n        X = self.embedding(X)  # embedding后shape:(batch_size, seq_len, embedding_size)\n        X = X.transpose(0, 1)  # 将第一和第二维度进行调换。 X shape:(seq_len, batch_size, embedding_size)\n        out, state = self.rnn(X)\n        # 此处我们只需要out输出单词序列\n        out = self.dense(out)\n        out = out.transpose(0, 1)  # 还原初始shape\n        return out, state","execution_count":14},{"metadata":{"id":"464E91107F59466DA8D3F18637E6B6A5","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"(torch.Size([4, 7, 10]), 2)"},"transient":{},"execution_count":15}],"source":"# 查看下decoder的直观效果\ndecoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\nstate = decoder.init_state(encoder(x))\nout, state = decoder(x, state)\nout.shape, len(state)","execution_count":15},{"metadata":{"id":"3FB7138E329540268F7B70C91B3B5DB2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"tensor([[1, 0, 0],\n        [4, 5, 0]])"},"transient":{},"execution_count":16}],"source":"# 由于前面输入语料进行了补全\n# 进行损失值计算时，补全的语料为无效部分\n# 此时需要一个使预测结果补全部分无效化的函数\ndef SequenceMask(X, X_len,value=0):\n    maxlen = X.size(1)\n    mask = torch.arange(maxlen)[None, :].to(X_len.device) < X_len[:, None]   \n    X[~mask]=value\n    return X\n# 看下效果\nX = torch.tensor([[1,2,3], [4,5,6]])\nSequenceMask(X,torch.tensor([1,2]))","execution_count":16},{"metadata":{"id":"8BB44E133453463D8D87F46BEDFCFE8F","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"tensor(4.0295)"},"transient":{},"execution_count":17}],"source":"# 损失函数使用交叉熵\n# 由于涉及语料的有效长度，需要再定义\nclass MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n    # pred shape: (batch_size, seq_len, vocab_size)\n    # label shape: (batch_size, seq_len)\n    # valid_length shape: (batch_size, )\n    def forward(self, pred, label, valid_length):\n        # the sample weights shape should be (batch_size, seq_len)\n        weights = torch.ones_like(label)\n        weights = SequenceMask(weights, valid_length).float()\n        self.reduction='none'\n        output=super(MaskedSoftmaxCELoss, self).forward(pred.transpose(1,2), label)\n        return (output*weights).mean(dim=1)\n\n# 查看下效果\nloss = MaskedSoftmaxCELoss()\nloss(torch.ones((3, 4, 10)), torch.ones((3,4),dtype=torch.long), torch.tensor([4,3,0])).sum()","execution_count":17},{"metadata":{"id":"3EA015E423D74EA48634CB081C89C426","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 训练函数\ndef train_ch7(model, data_iter, lr, num_epochs):\n    # model.to(device)\n    loss = MaskedSoftmaxCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    for epoch in range(num_epochs):\n        l_sum, num_tokens_sum = 0.0, 0.0\n        for data in data_iter:\n            X, X_valid_len, Y, Y_valid_len = data\n            # 由于decoder部分的输入组成为: BOS ...words EOS。 易知包含两类特殊标签\n            # Y作为decoder输入是去除EOS标签，作为输出时则去除BOS标签，最终有效长度需再-1\n            Y_input, Y_label, Y_valid_len = Y[:, :-1], Y[:, 1:], Y_valid_len-1  # ??\n            \n            Y_hat, _ = model(X, Y_input, X_valid_len, Y_valid_len)\n            l = loss(Y_hat, Y_label, Y_valid_len).sum()\n            l.backward()\n            optimizer.zero_grad()\n            with torch.no_grad():\n                d2l.grad_clipping_nn(model, 5)\n            num_tokens = Y_valid_len.sum().item()\n            optimizer.step()\n            l_sum += l.sum().item()\n            num_tokens_sum += num_tokens\n        if epoch % 50 == 0:\n            print(\"epoch {0:4d},loss {1:.3f}, time {2:.1f} sec\".format( \n                  epoch, (l_sum/num_tokens_sum), time.time()-tic))","execution_count":18},{"metadata":{"id":"082E26BF4F53414A804AA25954371B48","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"error","ename":"TypeError","evalue":"train_ch7() takes 4 positional arguments but 5 were given","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-b3fb641b7a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncoderDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_ch7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: train_ch7() takes 4 positional arguments but 5 were given"]}],"source":"embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\nbatch_size, num_examples, max_len = 64, 1e3, 10\nlr, num_epochs, ctx = 0.005, 300, d2l.try_gpu()\nsrc_vocab, tgt_vocab, train_iter = d2l.load_data_nmt(\n    batch_size, max_len,num_examples)\nencoder = Seq2SeqEncoder(\n    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\ndecoder = Seq2SeqDecoder(\n    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\nmodel = d2l.EncoderDecoder(encoder, decoder)\ntrain_ch7(model, train_iter, lr, num_epochs)","execution_count":19},{"metadata":{"id":"6655B338D12845F4823E90C240662134","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}