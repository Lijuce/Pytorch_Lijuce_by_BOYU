{"cells":[{"outputs":[],"execution_count":3,"source":"!pip install torchtext\nimport torch\nimport numpy as np\nimport sys\nsys.path.append(\"/home/kesci/input\")\nimport d2lzh1981 as d2l","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"8C3E508BDA744206815521B2D1096F32","scrolled":false}},{"metadata":{"id":"8384D8DBB7BE42978DA038BD85337955","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 获取数据\nbatch_size = 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size,root='/home/kesci/input/FashionMNIST2065')","execution_count":5},{"metadata":{"id":"46B89332F9EC4EB48A6E4E06BBF4C188","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 定义模型参数\nnum_inputs, num_outputs, num_hiddens = 784, 10, 256  #输入像素28*28=784 输出类别10（种） 隐藏层单元个数256\n\n# 第一层权重/偏置 W1/b1\nW1 = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_hiddens)), dtype=torch.float)  \nb1 = torch.zeros(num_hiddens, dtype=torch.float)\n# 第二层(隐藏层)权重/偏置 W2/b2  \nW2 = torch.tensor(np.random.normal(0, 0.01, (num_hiddens, num_outputs)), dtype=torch.float)\nb2 = torch.zeros(num_outputs, dtype=torch.float)\n\n# 合并所有参数，赋能梯度\nparams = [W1, b1, W2, b2]\nfor param in params:\n    param.requires_grad_(requires_grad=True)","execution_count":30},{"metadata":{"id":"11599ADB190D4238BC37C46E8B7E842A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 定义激活函数\ndef relu(x):\n    return torch.max(input=x, other=torch.tensor(0.0))","execution_count":8},{"metadata":{"id":"8FB24D08321146AB8CDDAE9188450CFF","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 定义网络\ndef net(x):\n    x = x.view((-1, num_inputs))\n    H = relu(torch.mm(x, W1) + b1)\n    return torch.mm(H, W2) + b2","execution_count":21},{"metadata":{"id":"465D6D72695C49488DD74B3821F754ED","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 定义损失函数\nloss = torch.nn.CrossEntropyLoss()","execution_count":12},{"metadata":{"id":"B3FEE9CAD3134BFF830D58D91BB0AF7D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 训练\ndef train_MLP(net, epoch_nums, train_iter, test_iter,\n              batch_size, loss, params, lr=None, optimizer=None):\n    for epoch in range(epoch_nums):\n        train_loss_sum, train_acc_sum, n = 0, 0, 0\n        for x,y in train_iter:\n            y_hat = net(x)  # 一个batchsize的输入x,得预测值\n            _loss = loss(y_hat, y).sum()  # 与真实值对比得损失值(总和)\n            # 梯度清零\n            if params is not None and params[0].grad is not None:\n                for param in params:\n                    param.grad.data.zero_()\n            # 梯度求解-反向传播BP\n            _loss.backward()\n            # 参数优化\n            if optimizer is None:\n                d2l.sgd(params, lr, batch_size)\n            # optimizer.step()\n            # loss是个标量，在pytorch里用item取出这个唯一的元素,最终目的是取一个epoch的loss平均值\n            train_loss_sum += _loss.item()\n            # 训练中预测准确的个数\n            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n            n += y.shape[0]  # 总输出个数，用于计算准确率\n        test_acc = d2l.evaluate_accuracy(test_iter, net)\n        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n              % (epoch + 1, train_loss_sum / n, train_acc_sum / n, test_acc))","execution_count":34},{"metadata":{"id":"BCF0D32E21B2415E8D7EF47CEFB2A524","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"epoch 1, loss 0.0019, train acc 0.822, test acc 0.791\nepoch 2, loss 0.0017, train acc 0.845, test acc 0.824\nepoch 3, loss 0.0015, train acc 0.855, test acc 0.841\nepoch 4, loss 0.0014, train acc 0.864, test acc 0.844\nepoch 5, loss 0.0014, train acc 0.868, test acc 0.840\n","name":"stdout"}],"source":"num_epochs, lr = 5, 100.0\ntrain_MLP(net, num_epochs, train_iter, test_iter, batch_size, loss, params, lr)","execution_count":35},{"metadata":{"id":"761505294C3A436D8E953E89E67D660F","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"epoch 1, loss 0.0011, train acc 0.892, test acc 0.858\nepoch 2, loss 0.0011, train acc 0.894, test acc 0.878\nepoch 3, loss 0.0011, train acc 0.898, test acc 0.879\nepoch 4, loss 0.0011, train acc 0.899, test acc 0.877\nepoch 5, loss 0.0010, train acc 0.901, test acc 0.854\n","name":"stdout"}],"source":"d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr)","execution_count":37}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}