{"cells":[{"outputs":[],"execution_count":1,"source":"import torch \nimport torch.nn as nn\n\n# 二维互运算操作\ndef corr2d(X, K):\n    H, W = X.shape  # 数组维度\n    h, w = K.shape\n    Y = torch.zeros(H-h+1, W-w+1)  # 计算结果数组维度\n    for i in range(Y.shape[0]):\n        for j in range(Y.shape[1]):\n            Y[i, j] = (X[i: i+h, j: j+w] * K).sum()\n    return Y\n    ","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"4B0520ED2C7949168003CDD35C893864","scrolled":false}},{"metadata":{"id":"E8F836D9D38449F695D3204C9887BDC0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 3.,  8.],\n        [18., 23.],\n        [33., 38.]])\n","name":"stdout"}],"source":"# 查看下效果\nX = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\nK = torch.tensor([[2, 3]])\nY = corr2d(X, K)\nprint(Y)","execution_count":5},{"metadata":{"id":"A031F38B72C9487C871A703E6324825E","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 构建二维卷积层:该层参数包括卷积核和标量偏置\nclass Conv2D(nn.Module):\n    def __init__(self, kernel_size):\n        super(Conv2D, self).__init__()\n        self.weight = nn.Parameter(torch.randn(kernel_size))\n        self.bias = nn.Parameter(torch.randn(1))\n        \n    def forward(self, x):\n        return corr2d(x, self.weight) + self.bias","execution_count":3},{"metadata":{"id":"F14D734CF45F4F24B04C60B51293DE2A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n        [1., 1., 0., 0., 0., 0., 1., 1.],\n        [1., 1., 0., 0., 0., 0., 1., 1.],\n        [1., 1., 0., 0., 0., 0., 1., 1.],\n        [1., 1., 0., 0., 0., 0., 1., 1.],\n        [1., 1., 0., 0., 0., 0., 1., 1.]])\ntensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])\n","name":"stdout"}],"source":"# 构造一张6X8的图像，中间4列为黑（0），其余为白（1），希望检测到颜色边缘。\n# 标签是一个6X7的二维数组，第2列是1（从1到0的边缘），第6列是-1（从0到1的边缘）\nX = torch.ones(6, 8)\nY = torch.zeros(6, 7)\nX[:, 2: 6] = 0\nY[:, 1] = 1\nY[:, 5] = -1\nprint(X)\nprint(Y)","execution_count":21},{"metadata":{"id":"FA7D48FAD385404994AB2D97B2A55506","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Step 5, loss 5.529\nStep 10, loss 1.453\nStep 15, loss 0.395\nStep 20, loss 0.109\nStep 25, loss 0.030\nStep 30, loss 0.008\ntensor([[ 0.9763, -0.9771]])\ntensor([0.0005])\n","name":"stdout"}],"source":"# 对以上自行构造的图像，希望用1X2的卷积层，学习检测边缘\nconv2d = Conv2D(kernel_size=(1, 2))\nstep = 30\nlr = 0.01\nfor i in range(step):\n    Y_hat = conv2d(X)\n    l = ((Y_hat - Y) ** 2).sum()  # 损失值计算\n    l.backward()\n    # 优化器优化（梯度下降，此处无直接使用某个优化器）\n    conv2d.weight.data -= lr * conv2d.weight.grad\n    conv2d.bias.data -= lr * conv2d.bias.grad\n    \n    # 梯度清零\n    conv2d.weight.grad.zero_()\n    conv2d.bias.grad.zero_()\n    if (i + 1) % 5 == 0:  # 每5次迭代输出损失值观察\n        print('Step %d, loss %.3f' % (i + 1, l.item()))\nprint(conv2d.weight.data)\nprint(conv2d.bias.data)","execution_count":25},{"metadata":{"id":"4BFFE0B77539489588FE4B7465632137","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Y.shape:  torch.Size([4, 3, 3, 5])\nweight.shape:  torch.Size([3, 2, 3, 5])\nbias.shape:  torch.Size([3])\n","name":"stdout"}],"source":"# pytorch简洁实现卷积层\n# 主要用到nn模块的Conv2d类\nX = torch.rand(4, 2, 3, 5)  # 批量大小4 通道数2 \nconv2d = nn.Conv2d(in_channels=2, out_channels=3, kernel_size=(3, 5), stride=1, padding=(1, 2))\nY = conv2d(X)\n# 从Y输出结果看，由于out_channals=3致使通道数发生变化\n# 由于卷积核大小、步幅和填充参数设置合理，输出与输入形状一致\nprint('Y.shape: ', Y.shape)  \nprint('weight.shape: ', conv2d.weight.shape)\nprint('bias.shape: ', conv2d.bias.shape)","execution_count":36},{"metadata":{"id":"6314EF540316481196D39A1DECD8FC05","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[16., 17., 18., 19.],\n          [20., 21., 22., 23.],\n          [24., 25., 26., 27.],\n          [28., 29., 30., 31.]]]])\ntensor([[[[ 5.,  6.,  7.,  7.],\n          [13., 14., 15., 15.]],\n\n         [[21., 22., 23., 23.],\n          [29., 30., 31., 31.]]]])\n","name":"stdout"}],"source":"# pytorch简洁实现池化层\n# 主要用到nn模块的MaxPool2d最大池化层类\nX = torch.arange(32, dtype=torch.float32).view(1, 2, 4, 4)  # 批量大小1 通道2  高宽4,4的图像数据\npool2d = nn.MaxPool2d(kernel_size=3, padding=1, stride=(2,1))\nY = pool2d(X)\nprint(X)\nprint(Y)","execution_count":38},{"metadata":{"id":"0BA80C20980C4A40A9D7334820165B18","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}